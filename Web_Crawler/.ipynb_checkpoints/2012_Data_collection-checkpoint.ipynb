{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蘋果日報already sampled\n",
    "# 馬英九 udn 2012\n",
    "ma_url_udn = ['https://udndata.com/ndapp/Searchdec?udndbid=udnfree&page={}&sharepage=50&select=1&kind=2&SearchString=%B0%A8%AD%5E%A4E%2B%A4%E9%B4%C1%3E%3D20111122%2B%A4%E9%B4%C1%3C%3D20120113%2B%B3%F8%A7O%3D%C1p%A6X%B3%F8%7C%B8g%C0%D9%A4%E9%B3%F8%7C%C1p%A6X%B1%DF%B3%F8%7CUpaper&_ga=2.206757207.515555858.1594973765-1030984037.1590050258'.format(i) for i in range(1, 37)]\n",
    "headers_ma_udn = []\n",
    "news_url_ma_udn = []\n",
    "time_dt_ma_udn = []\n",
    "time_nw_ma_udn = []\n",
    "\n",
    "for i in ma_url_udn:\n",
    "    udn_res = requests.get(i)\n",
    "    udn_soup = BeautifulSoup(udn_res.text, 'lxml')\n",
    "    udn_newslist= udn_soup.find_all('div', class_ = 'list')\n",
    "    for t in udn_newslist:\n",
    "        title_sect = t.find_all('h2')\n",
    "\n",
    "    for t in title_sect:\n",
    "        headers_ma_udn.append(t.find('a').text)\n",
    "\n",
    "    url_sect = [t.find('a') for t in title_sect]\n",
    "    for url in url_sect:\n",
    "        news_url_ma_udn.append('https://udn.com' + url['href'])\n",
    "\n",
    "    for t in udn_newslist:\n",
    "        time_tag = t.find_all('span')\n",
    "    for t in time_tag:\n",
    "        time_dt_ma_udn.append(t.text)\n",
    "    for i in time_dt_ma_udn:\n",
    "        time_nw_ma_udn.append(i.replace(i[10:], ''))\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "media_ma_udn= []\n",
    "for i in range(len(headers_ma_udn)):\n",
    "    media_ma_udn.append('UDN')\n",
    "    \n",
    "time_cl_ma = []\n",
    "for i in time_dt_ma_udn:\n",
    "    time_cl_ma.append(i.replace(i[10:], ''))\n",
    "    \n",
    "df_ma_udn = pd.DataFrame(\n",
    "{\n",
    "    'titles' : headers_ma_udn,\n",
    "    'links' : news_url_ma_udn,\n",
    "    'time' : time_cl_ma,\n",
    "    'media': media_ma_udn\n",
    "})\n",
    "\n",
    "df_ma_udn = df_ma_udn.drop_duplicates('titles', 'first', inplace = False)\n",
    "df_ma_udn.to_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/馬英九_2012_udn.csv', \\\n",
    "                  encoding = 'utf_8_sig', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#蔡英文udn2012\n",
    "tsai_url_udn = ['https://udndata.com/ndapp/Searchdec?udndbid=udnfree&page={}&SearchString=%BD%B2%AD%5E%A4%E5%2B%A4%E9%B4%C1%3E%3D20111122%2B%A4%E9%B4%C1%3C%3D20120113%2B%B3%F8%A7%4F%3D%C1%70%A6%58%B3%F8%7C%B8%67%C0%D9%A4%E9%B3%F8%7C%C1%70%A6%58%B1%DF%B3%F8%7CUpaper&sharepage=50&select=1&kind=2'.format(i) for i in range(1, 37)]\n",
    "headers_tsai_udn = []\n",
    "news_url_tsai_udn = []\n",
    "time_dt_tsai_udn = []\n",
    "time_nw_tsai_udn = []\n",
    "\n",
    "for i in tsai_url_udn:\n",
    "    udn_res = requests.get(i)\n",
    "    udn_soup = BeautifulSoup(udn_res.text, 'lxml')\n",
    "    udn_newslist= udn_soup.find_all('div', class_ = 'list')\n",
    "    for t in udn_newslist:\n",
    "        title_sect = t.find_all('h2')\n",
    "\n",
    "    for t in title_sect:\n",
    "        headers_tsai_udn.append(t.find('a').text)\n",
    "\n",
    "    url_sect = [t.find('a') for t in title_sect]\n",
    "    for url in url_sect:\n",
    "        news_url_tsai_udn.append('https://udn.com' + url['href'])\n",
    "\n",
    "    for t in udn_newslist:\n",
    "        time_tag = t.find_all('span')\n",
    "    for t in time_tag:\n",
    "        time_dt_tsai_udn.append(t.text)\n",
    "    for i in time_dt_tsai_udn:\n",
    "        time_nw_tsai_udn.append(i.replace(i[10:], ''))\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "media_tsai_udn= []\n",
    "for i in range(len(headers_tsai_udn)):\n",
    "    media_tsai_udn.append('UDN')\n",
    "    \n",
    "time_cl_tsai = []\n",
    "for i in time_dt_tsai_udn:\n",
    "    time_cl_tsai.append(i.replace(i[10:], ''))\n",
    "    \n",
    "df_tyw_udn = pd.DataFrame(\n",
    "{\n",
    "    'titles' : headers_tsai_udn,\n",
    "    'links' : news_url_tsai_udn,\n",
    "    'time' : time_cl_tsai,\n",
    "    'media': media_tsai_udn\n",
    "})\n",
    "df_tyw_udn.drop_duplicates('titles', 'first', inplace = False)\n",
    "df_tyw_udn.to_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/蔡英文_2012_udn.csv', \\\n",
    "                  encoding = 'utf_8_sig', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 馬英九 2012 自由時報\n",
    "headers_m = []\n",
    "news_url_m = []\n",
    "time_dt_m = []\n",
    "media_m = []\n",
    "ma_lib_url = ['https://news.ltn.com.tw/search?keyword=%E9%A6%AC%E8%8B%B1%E4%B9%9D&conditions=and&start_time=2011-11-22&end_time=2012-01-13&page={}'.format(i) for i in range(1, 120)]\n",
    "for i in ma_lib_url:\n",
    "        res_news = requests.get(i)\n",
    "        newslist_soup = BeautifulSoup(res_news.text, 'lxml')\n",
    "\n",
    "        for newslist in newslist_soup.find_all('div', class_ = 'whitecon'):\n",
    "            li_label = newslist.find_all('li')\n",
    "\n",
    "          # 新聞標題\n",
    "        for t in li_label:\n",
    "            headers_m.append(t.find('a').text)\n",
    "\n",
    "        # 新聞連結\n",
    "        url_sect = [t.find('a') for t in li_label]\n",
    "        for t in url_sect:\n",
    "            news_url_m.append(t.get('href'))\n",
    "\n",
    "        # 時間\n",
    "        for t in li_label:\n",
    "            time_dt_m.append(t.find('span').text)\n",
    "\n",
    "        time.sleep(2)\n",
    "    \n",
    "for i in range(len(headers_m)):\n",
    "    media_m.append('Liberal Times')\n",
    "\n",
    "time_nw_m = []\n",
    "for i in time_dt_m:\n",
    "    time_nw_m.append(i.replace(i[10:], ''))\n",
    "\n",
    "df_ma_lib = pd.DataFrame(\n",
    "{\n",
    "    'titles' : headers_m,\n",
    "    'links' : news_url_m,\n",
    "    'time' : time_nw_m,\n",
    "    'media': media_m\n",
    "})\n",
    "df_ma_lib.drop_duplicates('titles', 'first', inplace = False)\n",
    "\n",
    "df_ma_lib.to_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/馬英九_2012_lib.csv', \\\n",
    "                  encoding = 'utf_8_sig', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蔡英文 2012 自由時報\n",
    "headers_tsai_udn = []\n",
    "news_url_tsai_udn = []\n",
    "time_dt_tsai_udn = []\n",
    "time_nw_tsai_udn = []\n",
    "\n",
    "tsai_lib_url = ['https://news.ltn.com.tw/search?keyword=%E8%94%A1%E8%8B%B1%E6%96%87&conditions=and&start_time=2011-11-22&end_time=2012-01-13&page={}'.format(i) for i in range(1, 117)]\n",
    "\n",
    "headers = []\n",
    "news_url = []\n",
    "time_dt = []\n",
    "media = []\n",
    "\n",
    "for i in tsai_lib_url:\n",
    "        res_news = requests.get(i)\n",
    "        newslist_soup = BeautifulSoup(res_news.text, 'lxml')\n",
    "\n",
    "        for newslist in newslist_soup.find_all('div', class_ = 'whitecon'):\n",
    "            li_label = newslist.find_all('li')\n",
    "\n",
    "          # 新聞標題\n",
    "        for t in li_label:\n",
    "            headers.append(t.find('a').text)\n",
    "\n",
    "        # 新聞連結\n",
    "        url_sect = [t.find('a') for t in li_label]\n",
    "        for t in url_sect:\n",
    "            news_url.append(t.get('href'))\n",
    "\n",
    "        # 時間\n",
    "        for t in li_label:\n",
    "            time_dt.append(t.find('span').text)\n",
    "\n",
    "        time.sleep(2)\n",
    "    \n",
    "media = []\n",
    "for i in range(len(headers)):\n",
    "    media.append('Liberal Times')\n",
    "\n",
    "time_nw_tsai = []\n",
    "for i in time_dt:\n",
    "    time_nw_tsai.append(i.replace(i[10:], ''))\n",
    "time_nw_tsai\n",
    "\n",
    "df_tsai_lib = pd.DataFrame(\n",
    "{\n",
    "    'titles' : headers,\n",
    "    'links' : news_url,\n",
    "    'time' : time_nw_tsai,\n",
    "    'media': media\n",
    "})\n",
    "df_tsai_lib.drop_duplicates('titles', 'first', inplace = True)\n",
    "\n",
    "df_tsai_lib.to_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/蔡英文_2012_lib.csv', \\\n",
    "                  encoding = 'utf_8_sig', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 馬英九 中國時報 2012\n",
    "ma_url_cht = ['https://www.chinatimes.com/search/%E9%A6%AC%E8%8B%B1%E4%B9%9D?page={}&chdtv'.format(i) for i in range(362 ,365)]\n",
    "\n",
    "headers_cht_ma = []\n",
    "news_url_cht_ma = []\n",
    "time_dt_cht_ma = []\n",
    "\n",
    "for i in ma_url_cht:\n",
    "    res_news = requests.get(i)\n",
    "    newslist_soup = BeautifulSoup(res_news.text, 'lxml')\n",
    "\n",
    "    for newslist in newslist_soup.find_all('div', class_ = 'item-list article-list'):\n",
    "        title_sect = newslist.find_all('h3')\n",
    "\n",
    "    for t in title_sect:\n",
    "        headers_cht_ma.append(t.find('a').text)\n",
    "\n",
    "    url_sect = [t.find('a') for t in title_sect]\n",
    "    for t in url_sect:\n",
    "        news_url_cht_ma.append(t.get('href'))\n",
    "\n",
    "    for i in newslist_soup.find_all('div', class_ = 'item-list article-list'):\n",
    "        time_test = i.find_all('div', class_ = 'meta-info')\n",
    "    for t in time_test:\n",
    "        time_dt_cht_ma.append(t.find('time').text)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "media_cht_ma = []\n",
    "for i in range(len(headers_cht_ma)):\n",
    "    media_cht_ma.append('China Times')\n",
    "    \n",
    "time_ma_cht = []\n",
    "for i in time_dt_cht_ma:\n",
    "    time_ma_cht.append(i.replace(i[:5], ''))\n",
    "df_ma_cht = pd.DataFrame(\n",
    "{\n",
    "    'titles' : headers_cht_ma,\n",
    "    'links' : news_url_cht_ma,\n",
    "    'time' : time_dt_cht_ma,\n",
    "    'media': media_cht_ma\n",
    "})\n",
    "\n",
    "df_ma_cht.drop_duplicates('titles', 'first', inplace = False)\n",
    "df_ma_cht.to_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/馬英九_2012_cht.csv', \\\n",
    "                  encoding = 'utf_8_sig', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蔡英文 中國時報 2012 \n",
    "tsai_cht = ['https://www.chinatimes.com/search/%E8%94%A1%E8%8B%B1%E6%96%87?page={}&chdtv'.format(i) for i in range(1711 ,1746)]\n",
    "\n",
    "headers_cht_tsai = []\n",
    "news_url_cht_tsai = []\n",
    "time_dt_cht_tsai = []\n",
    "\n",
    "for i in tsai_cht:\n",
    "    res_news = requests.get(i)\n",
    "    newslist_soup = BeautifulSoup(res_news.text, 'lxml')\n",
    "\n",
    "    for newslist in newslist_soup.find_all('div', class_ = 'item-list article-list'):\n",
    "        title_sect = newslist.find_all('h3')\n",
    "\n",
    "    for t in title_sect:\n",
    "        headers_cht_tsai.append(t.find('a').text)\n",
    "\n",
    "    url_sect = [t.find('a') for t in title_sect]\n",
    "    for t in url_sect:\n",
    "        news_url_cht_tsai.append(t.get('href'))\n",
    "\n",
    "    for i in newslist_soup.find_all('div', class_ = 'item-list article-list'):\n",
    "        time_test = i.find_all('div', class_ = 'meta-info')\n",
    "    for t in time_test:\n",
    "        time_dt_cht_tsai.append(t.find('time').text)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "media_cht_tsai = []\n",
    "for i in range(len(headers_cht_tsai)):\n",
    "    media_cht_tsai.append('China Times')\n",
    "    \n",
    "time_tsai_cht = []\n",
    "for i in time_dt_cht_tsai:\n",
    "    time_tsai_cht.append(i.replace(i[:5], ''))\n",
    "df_tsai_cht = pd.DataFrame(\n",
    "{\n",
    "    'titles' : headers_cht_tsai,\n",
    "    'links' : news_url_cht_tsai,\n",
    "    'time' : time_dt_cht_tsai,\n",
    "    'media': media_cht_tsai\n",
    "})\n",
    "\n",
    "df_tsai_cht.drop_duplicates('titles', 'first', inplace = False)\n",
    "df_tsai_cht.to_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/蔡英文_2012_cht.csv', \\\n",
    "                  encoding = 'utf_8_sig', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9623"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data organisation\n",
    "ma_apple = pd.read_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/馬英九_2012_applenews.csv')\n",
    "ma_udn = pd.read_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/馬英九_2012_udn.csv')\n",
    "ma_lib = pd.read_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/馬英九_2012_lib.csv')\n",
    "ma_cht = pd.read_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/馬英九_2012_cht.csv')\n",
    "\n",
    "tsai_apple = pd.read_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/蔡英文_2012_applenews.csv')\n",
    "tsai_lib = pd.read_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/馬英九_2012_lib.csv')\n",
    "tsai_cht = pd.read_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/蔡英文_2012_cht.csv')\n",
    "tsai_udn = pd.read_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/蔡英文_2012_udn.csv')\n",
    "\n",
    "news_2012 = pd.concat([ma_apple, ma_udn, ma_lib, ma_cht, tsai_apple, tsai_lib, tsai_cht, tsai_udn])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_2012 = news_2012.drop_duplicates('titles', 'first', inplace = False)\n",
    "news_2012.to_csv('/Users/garday/Documents/MY499/Data Collection/Data/2012/news_2012.csv', \\\n",
    "                  encoding = 'utf_8_sig', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
